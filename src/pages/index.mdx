---
layout: '@layouts/IndexLayout.astro'
title: Kanji usage frequency
subtitle: Datasets built from various Japanese language corpora
---

## About

This project is an attempt to collect a big set of comparable data
about Japanese kanji (漢字) usage frequency from various sources.

### History

In 2014-2015, I started this project to answer the following question:

> "In which order should I learn Japanese kanji if I have a goal
> of reading some specific type of texts, e.g. news?"

The data was collected from the following sources:

- [Aozora Bunko](https://www.aozora.gr.jp/)
- [Japanese Wikipedia](https://ja.wikipedia.org/)
- Several popular Japanese news websites:
  [Asahi](https://www.asahi.com/),
  [Mainichi](https://mainichi.jp/), etc.
- Twitter

However, this first attempt lacked sufficient research and technical effort,
and the resulting datasets have multiple issues, described in the
[attached readme](https://github.com/scriptin/kanji-frequency/tree/master/data2015/README.md).

### Current version

This new version solves the most of the aforementioned issues,
but unfortunately has some new problems:

- **Twitter dataset was exluded**:
  - Twitter API no longer has a free teer,
  - Changes in the organization management and staff layoffs
    resulted in insufficient content moderation,
- **News dataset is much smaller**:
  - Most news on popular websites are now behind a paywall,
    making it impractical to create a crawler/scraper,
  - [Japanese Wikinews](https://ja.wikinews.org/) has way
    less articles than a typical big news website.

Despite these problems, this new dataset has a better format,
which includes not only overall character frequency data,
but also documents count, i.e. "in how many documents
in this corpus this particular kanji appears?"

## Coverage of corpora

### Character coverage

import CharCoverageChartI18n from '@components/chart/CharCoverageChartI18n.astro';

<CharCoverageChartI18n
  class="mb-4"
  axisLabels={{
    x: 'First N most frequent characters',
    y: 'Coverage of corpus, % of all kanji',
  }}
/>

This diagram shows how many of the first most frequent kanji one needs
to know in order to be able to recognize a given fraction of kanji characters
in each corpus.

For example, if a person knows the first 100 most frequent kanji from
the "news" dataset (green line), they are able to recognize ~45% of kanji
in news articles. Knowing 300 most frequenct kanji will ensure ~72% of
recognition. Knowing 1000 results in ~96% recognition.

See [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law)

### Document coverage

import DocCoverageChartI18n from '@components/chart/DocCoverageChartI18n.astro';

<DocCoverageChartI18n
  class="mb-4"
  axisLabels={{
    x: 'Nth most frequent character',
    y: 'Coverage of corpus, % of all docs/texts',
  }}
/>

This diagram shows how many of the documents/texts in each dataset contain
every Nth most frequent character. Character frequency in this case is defined
as the number of documents/texts which contain this character.

For example, the 1st most popular kanji in the "news" dataset (green line)
is present in almost 100% of all documents, while the 100th most popular
appreas in ~26% of documents.

## Want to contribute?

Start by looking through the [list of issues](https://github.com/scriptin/kanji-frequency/issues),
and open a new issue if you found a problem or want to otherwise improve this dataset.
